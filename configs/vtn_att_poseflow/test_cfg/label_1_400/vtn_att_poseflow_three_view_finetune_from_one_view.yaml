task: ISLR
data:
  model_name: VTNHCPF_Three_view
  base_url: /mnt/disk2/anhnct/Hand-Sign-Recognition/data/VN_SIGN
  dataset_name: VN_SIGN
  temporal_stride: 2
  num_output_frames: 16
  crop_two_hand: true
  transform_cfg:
    index_setting:
      - segment #train_p
      - pad #train_m
      - segment #test_p
      - pad #test_m
  vid_transform:
    IMAGE_SIZE: 224
    NORM_MEAN_IMGNET: [0.485, 0.456, 0.406]
    NORM_STD_IMGNET: [0.229, 0.224, 0.225]
  SHOULDER_DIST_EPSILON: 1.2
  WRIST_DELTA: 0.15
  label_folder: label_1_400
  data_type: 1_400_three_view_ord1
training:
  test: True
  label_smoothing: 0
  device: cuda:2
  overwrite: true
  log_freq: 1
  experiment_name: "vtn_att_poseflow three view finetune from one view (1-400) (Testing)"
  model_dir: results/vtn_att_poseflow/vn_sign
  random_seed: 42
  shuffle: True
  num_workers: 12
  prefetch_factor: 4
  batch_size: 2 #to-debug!
  total_epoch: 100 #to-debug!
  learning_rate: 0.0001
  save_checkpoints: true
  scheduler_factor: 0.1
  scheduler_patience: 5
  plot_loss: true
  plot_lr: true
  plot_acc: true
  criterion: MyCustomLoss
  optimzer: Adam
  lr_scheduler: StepLR
  top_k: 5
  print_stats: true
  pretrained: true
  pretrained_model: CK/VTN/1-400/vtn_att_poseflow three view finetune from one view (1-400)/best_checkpoints.pth
  lr_step_size: 10
  gamma: 0.8
  num_accumulation_steps: 4
  patience: 15
  verbose: true
  delta: 0
  is_early_stopping: true
  gradient_clip_val: 1
  w_decay: 1e-4
  log_train_step: true
  log_steps: 50
  evaluate_step: 250
  evaluate_strategy: epoch

inference:
  batch_size: 8
model:
  num_classes: 400
  num_heads: 8
  num_layers: 4
  embed_size: 512
  cnn: rn34
  freeze_layers: 5 # free layers in cnn
  dropout: 0.1

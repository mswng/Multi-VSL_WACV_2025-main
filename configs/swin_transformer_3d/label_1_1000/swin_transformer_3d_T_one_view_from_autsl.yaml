task: ISLR
data:
  model_name: swin_transformer
  base_url: data
  dataset_name: VN_SIGN
  temporal_stride: 2
  num_output_frames: 16
  crop_two_hand: true
  transform_cfg:
    index_setting:
      - segment #train_p
      - pad #train_m
      - segment #test_p
      - pad #test_m
  vid_transform:
    IMAGE_SIZE: 224
    NORM_MEAN_IMGNET: [0.485, 0.456, 0.406]
    NORM_STD_IMGNET: [0.229, 0.224, 0.225]
  SHOULDER_DIST_EPSILON: 1.2
  WRIST_DELTA: 0.15
  label_folder: label_1_1000
  data_type: 1_1000_right_ord1
training:
  coefficient:
    cls_x: 1
    cts_x: 1
    cosine_x: 1
  label_smoothing: 0
  device: cuda:0
  overwrite: true
  log_freq: 1
  experiment_name: "Swin Transformer 3D Tiny for one view pretrained from AUTSL (1-1000)"
  model_dir: results/swin_transformer/vn_sign
  random_seed: 42
  shuffle: True
  num_workers: 12
  prefetch_factor: 4
  batch_size: 4 #to-debug!
  total_epoch: 300 #to-debug!
  learning_rate: 0.0001
  save_checkpoints: true
  scheduler_factor: 0.1
  scheduler_patience: 5
  plot_loss: true
  plot_lr: true
  plot_acc: true
  criterion: MyCustomLoss
  optimzer: Adam
  lr_scheduler: StepLR
  top_k: 5
  print_stats: true
  pretrained: true
  pretrained_model: checkpoints/swin_transformer/Swin Transformer 3D Tiny for one view of AUTSL pretrained on kinetics400 /autsl_best_checkpoints.pth
  lr_step_size: 5
  gamma: 0.5
  num_accumulation_steps: 5
  patience: 15
  verbose: true
  delta: 0
  is_early_stopping: true
  gradient_clip_val: 0
  w_decay: 0.02
  log_train_step: true
  log_steps: 50
  evaluate_step: 250
  evaluate_strategy: epoch

inference:
  batch_size: 8
model:
  num_classes: 1000
  